{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Main page Landing page Current workflow Image caption","title":"Main page"},{"location":"#main-page","text":"Landing page","title":"Main page"},{"location":"#current-workflow","text":"Image caption","title":"Current workflow"},{"location":"reference/make-model/","text":"make-model debug_filtering ( filter ) Edwards' dataset of host is filtered to one, specific taxonomy level and from it, all host genomes that represent this taxonomy level are chosen. Parameters: Name Type Description Default filter str A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def debug_filtering ( filter : str ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to one, specific taxonomy level and from it, all host genomes that represent this taxonomy level are chosen. Args: filter: A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) target = [ \"Clostridiales\" ] filenames = [] for name in target : for host in host_data : if host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ][ 'order' ]] == name : filenames . append ( host ) # list of paths to be returned filepaths = [ f \" { config [ 'HOST' ][ 'host_genomes' ] }{ host } .fna\" for host in filenames ] # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] temp_files_path = [ item for sublist in filepaths for item in sublist ] filenames = temp_files filepaths = temp_files_path print ( filenames ) # get list of taxid (labels in fastDNA) # labels = [] # for org in filenames: # try: # labels.append(\"_\".join(re.split(' |\\; |\\. |\\, ', host_data[org][\"lineage_names\"][-1]))) # except KeyError: # labels.append(\"_\".join(re.split(' |\\; |\\. |\\, ', virus_data[org][\"host\"][\"lineage_names\"][-1]))) labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filepaths , labels fasta_parallel ( file ) Reads FASTA files and returns parsed data. This function is run in parallel. Parameters: Name Type Description Default file str Path to FASTA file. required Returns: Type Description SeqRecord Parsed data from FASTA file as a SeqRecord object. Source code in fastdna-faiss\\make-model.py def fasta_parallel ( file : str ) -> SeqRecord : \"\"\"Reads FASTA files and returns parsed data. This function is run in parallel. Args: file: Path to FASTA file. Returns: SeqRecord: Parsed data from FASTA file as a SeqRecord object. \"\"\" record = SeqIO . read ( file , \"fasta\" ) return record hybrid_filtering ( filter , reps ) Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Additionally, virus genomes associated with each chosen host are also passed into model training. Parameters: Name Type Description Default filter str A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) required reps int A number of representatives chosen randomly at selected level (defined by filter ) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def hybrid_filtering ( filter : str , reps : int ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Additionally, virus genomes associated with each chosen host are also passed into model training. Args: filter: A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) reps: A number of representatives chosen randomly at selected level (defined by `filter`) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) for host in host_data : level = host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ][ 'family' ]] # tax level code filter_host [ level ] . append ( host ) # random sampling of a single host from a level random_level_host = { level : random . sample ( filter_host [ level ], len ( filter_host [ level ]) if len ( filter_host [ level ]) < reps else reps ) for level in filter_host } # print(random_level_host) # list with full paths random_level_host_paths = {} for level in random_level_host : random_level_host_paths . update ({ level : [ f \" { config [ 'HOST' ][ 'host_genomes' ] }{ host } .fna\" for host in random_level_host [ level ]]}) # add known viruses for level in random_level_host : to_add = [] for host in random_level_host [ level ]: try : # virus_sample = random.sample(hostvir_data[host]['virus_id'], len(random_level_host[level]) if len(random_level_host[level]) < reps else reps) #virus_sample = random.sample(hostvir_data[host]['virus_id'], 1) virus_sample = random . sample ( hostvir_data [ host ][ 'virus_id' ], len ( hostvir_data [ host ][ 'virus_id' ])) to_add . extend ( virus_sample ) except : continue random_level_host_paths [ level ] . extend ([ f \" { config [ 'VIRUS' ][ 'virus_genomes' ] }{ virus } .fna\" for virus in to_add ]) random_level_host [ level ] . extend ( to_add ) print ( random_level_host ) # list of filenames to be used filenames = list ( random_level_host . values ()) # print(filenames) # list of paths to be returned filepaths = list ( random_level_host_paths . values ()) # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] temp_files_path = [ item for sublist in filepaths for item in sublist ] filenames = temp_files filepaths = temp_files_path print ( filenames ) # get list of taxid (labels in fastDNA) labels = [] for org in filenames : try : labels . append ( \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ org ][ \"lineage_names\" ][ - 1 ]))) except KeyError : labels . append ( \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , virus_data [ org ][ \"host\" ][ \"lineage_names\" ][ - 1 ]))) #labels = [\"_\".join(re.split(' |\\; |\\. |\\, ', host_data[host][\"lineage_names\"][-1])) for host in filenames] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filepaths , labels main_procedure ( input_dir , out_dir , filter , dim , length , minn , maxn , epoch , thread , reps , rm , save_vec ) Main function of the module that runs model making. Parameters: Name Type Description Default input_dir str Path to directory with all host genomes. required out_dir str Path to directory where all output files are saved (chosen genomes - .fasta file, taxid list - .txt file, model file - .bin file) required filter str A taxonomy level by which filtering is conducted / A flag to filter through this function Todo filter argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future required dim int Dimensionality of vectors to be used during the training process. required length int Length of fragments of the genomes to be used during the training process. required minn int Minimum size of a k-mer to be used during the training process. required maxn int Maximum size of a k-mer to be used during the training process (it is advised to be kept the same as minn and less than 15, otherwise fastDNA fails ). required epoch int Number of training epochs (each added epoch increases runtime significantly, but in most cases increases model quality). required thread int Number of CPU threads to be used during training process (more threads - faster training, but higher CPU usage) required reps int A number of representatives chosen randomly at selected level (defined by filter ) required rm bool Remove potentially redundant files after model creation. Default is false and it is advised to be set default. required save_vec bool Enables saving of a readable model file .vec . Enabling this may significantly increase execution time. Default is 'false'. required Todo filter argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future Source code in fastdna-faiss\\make-model.py def main_procedure ( input_dir : str , out_dir : str , filter : str , dim : int , length : int , minn : int , maxn : int , epoch : int , thread : int , reps : int , rm : bool , save_vec : bool ): \"\"\"Main function of the module that runs model making. Args: input_dir: Path to directory with all host genomes. out_dir: Path to directory where all output files are saved (chosen genomes - `.fasta` file, taxid list - `.txt` file, model file - `.bin` file) filter: A taxonomy level by which filtering is conducted / A flag to filter through this function !!! todo `filter` argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future dim: Dimensionality of vectors to be used during the training process. length: Length of fragments of the genomes to be used during the training process. minn: Minimum size of a k-mer to be used during the training process. maxn: Maximum size of a k-mer to be used during the training process (it is advised to be kept the same as `minn` and **less than 15, otherwise fastDNA fails**). epoch: Number of training epochs (each added epoch increases runtime significantly, but in most cases increases model quality). thread: Number of CPU threads to be used during training process (more threads - faster training, but higher CPU usage) reps: A number of representatives chosen randomly at selected level (defined by `filter`) rm: Remove potentially redundant files after model creation. Default is `false` and it is advised to be set default. save_vec: Enables saving of a readable model file `.vec`. Enabling this may significantly increase execution time. Default is 'false'. !!! todo `filter` argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future \"\"\" # colorama init () # timeit start = timer () out_path = Path ( out_dir ) if not out_path . exists (): os . system ( f \"mkdir { str ( out_path ) } \" ) filenames = [] labels = [] if filter not in [ \"none\" , \"hybrid\" , \"debug\" ]: filenames , labels = tax_filtering ( filter , reps ) if filter == \"none\" : filenames , labels = no_filtering ( input_dir ) if filter == \"hybrid\" : filenames , labels = hybrid_filtering ( filter , reps ) if filter == \"debug\" : filenames , labels = debug_filtering ( filter ) # parse selected files and merge them into single fasta file; create labels file # records = [list(SeqIO.parse(f\"D:/praktyki2020/edwards2016/host/fasta/{file}.fna\", \"fasta\"))[0] for file in filenames] # for file, label in zip(filenames, labels): # print(f\"{file} - {label}\") if filter not in [ \"hybrid\" , \"debug\" ]: par = Parallel ( n_jobs =- 1 , verbose = 11 , pre_dispatch = 'all' , batch_size = \"auto\" , backend = \"loky\" )( delayed ( fasta_parallel )( f \" { input_dir }{ file } .fna\" ) for file in filenames ) if filter in [ 'hybrid' , \"debug\" ]: par = Parallel ( n_jobs =- 1 , verbose = 11 , pre_dispatch = 'all' , batch_size = \"auto\" , backend = \"loky\" )( delayed ( fasta_parallel )( file ) for file in filenames ) # print(par) # print(len(records)) # print(records) filtered_fasta_file = f \"random_train- { filter } -dim_ { dim } -len_ { length } .fasta\" with open ( f \" { out_dir }{ filtered_fasta_file } \" , \"w+\" ) as w_fh : SeqIO . write ( par , w_fh , \"fasta\" ) labels_file = f \"random_labels- { filter } -dim_ { dim } -len_ { length } .txt\" with open ( f \" { out_dir }{ labels_file } \" , \"w\" ) as fh : for label in labels : fh . write ( label + \" \\n \" ) # run fastDNA training model_file = f \"random_model- { filter } -dim_ { dim } -len_ { length } -epoch { epoch } \" if save_vec : os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna supervised -input { out_dir }{ filtered_fasta_file } -labels { out_dir }{ labels_file } -output { out_dir }{ model_file } -dim { dim } -length { length } -minn { minn } -maxn { maxn } -epoch { epoch } -thread { thread } -saveVec\" ) else : os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna supervised -input { out_dir }{ filtered_fasta_file } -labels { out_dir }{ labels_file } -output { out_dir }{ model_file } -dim { dim } -length { length } -minn { minn } -maxn { maxn } -epoch { epoch } -thread { thread } \" ) # par = Parallel(n_jobs=-1)(delayed(SeqIO.write)(records, \"D:/praktyki2020/edwards2016/host/random_phylum-training_fastDNA.fasta\", \"fasta\") for record in records) # SeqIO.write(records, \"X:/edwards2016/host/random_phylum-training_fastDNA.fasta\", \"fasta\") # print(f\"Written {len(records)} records.\") if rm : print ( \"removing\" ) os . system ( f \"rm { out_dir }{ filtered_fasta_file } \" ) os . system ( f \"rm { out_dir }{ labels_file } \" ) end = timer () runtime = end - start print ( f \" { Fore . GREEN } [make-model] Done in { runtime : .6f } \" ) no_filtering ( input_dir ) Edwards' dataset of host is not filtered and all genomes from selected directory are passed to model training. Parameters: Name Type Description Default input_dir str Path to directory with all host genomes. required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def no_filtering ( input_dir : str ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is not filtered and all genomes from selected directory are passed to model training. Args: input_dir: Path to directory with all host genomes. Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" filenames = [ path . split ( \"/\" )[ - 1 ] . split ( \".\" )[ 0 ] for path in glob . glob ( f \" { input_dir } *.fna\" )] print ( filenames ) # labels = [host_data[host][\"taxid\"] for host in filenames] labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] return filenames , labels tax_filtering ( filter , reps ) Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Parameters: Name Type Description Default filter str A taxonomy level by which filtering is conducted required reps int A number of representatives chosen randomly at selected level (defined by filter ) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def tax_filtering ( filter : str , reps : int ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Args: filter: A taxonomy level by which filtering is conducted reps: A number of representatives chosen randomly at selected level (defined by `filter`) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) for host in host_data : level = host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ]] # tax level code filter_host [ level ] . append ( host ) # random sampling of a single host from a level random_level_host = { level : random . sample ( filter_host [ level ], len ( filter_host [ level ]) if len ( filter_host [ level ]) < reps else reps ) for level in filter_host } print ( random_level_host ) # list of filenames to be used filenames = list ( random_level_host . values ()) # print(filenames) # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] filenames = temp_files print ( filenames ) # get list of taxid (labels in fastDNA) labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filenames , labels","title":"make-model"},{"location":"reference/make-model/#make-model_1","text":"","title":"make-model"},{"location":"reference/make-model/#make-model.debug_filtering","text":"Edwards' dataset of host is filtered to one, specific taxonomy level and from it, all host genomes that represent this taxonomy level are chosen. Parameters: Name Type Description Default filter str A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def debug_filtering ( filter : str ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to one, specific taxonomy level and from it, all host genomes that represent this taxonomy level are chosen. Args: filter: A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) target = [ \"Clostridiales\" ] filenames = [] for name in target : for host in host_data : if host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ][ 'order' ]] == name : filenames . append ( host ) # list of paths to be returned filepaths = [ f \" { config [ 'HOST' ][ 'host_genomes' ] }{ host } .fna\" for host in filenames ] # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] temp_files_path = [ item for sublist in filepaths for item in sublist ] filenames = temp_files filepaths = temp_files_path print ( filenames ) # get list of taxid (labels in fastDNA) # labels = [] # for org in filenames: # try: # labels.append(\"_\".join(re.split(' |\\; |\\. |\\, ', host_data[org][\"lineage_names\"][-1]))) # except KeyError: # labels.append(\"_\".join(re.split(' |\\; |\\. |\\, ', virus_data[org][\"host\"][\"lineage_names\"][-1]))) labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filepaths , labels","title":"debug_filtering()"},{"location":"reference/make-model/#make-model.fasta_parallel","text":"Reads FASTA files and returns parsed data. This function is run in parallel. Parameters: Name Type Description Default file str Path to FASTA file. required Returns: Type Description SeqRecord Parsed data from FASTA file as a SeqRecord object. Source code in fastdna-faiss\\make-model.py def fasta_parallel ( file : str ) -> SeqRecord : \"\"\"Reads FASTA files and returns parsed data. This function is run in parallel. Args: file: Path to FASTA file. Returns: SeqRecord: Parsed data from FASTA file as a SeqRecord object. \"\"\" record = SeqIO . read ( file , \"fasta\" ) return record","title":"fasta_parallel()"},{"location":"reference/make-model/#make-model.hybrid_filtering","text":"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Additionally, virus genomes associated with each chosen host are also passed into model training. Parameters: Name Type Description Default filter str A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) required reps int A number of representatives chosen randomly at selected level (defined by filter ) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def hybrid_filtering ( filter : str , reps : int ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Additionally, virus genomes associated with each chosen host are also passed into model training. Args: filter: A flag to filter through this function (TODO: this is not final, this will act as an actual filter value in the future) reps: A number of representatives chosen randomly at selected level (defined by `filter`) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) for host in host_data : level = host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ][ 'family' ]] # tax level code filter_host [ level ] . append ( host ) # random sampling of a single host from a level random_level_host = { level : random . sample ( filter_host [ level ], len ( filter_host [ level ]) if len ( filter_host [ level ]) < reps else reps ) for level in filter_host } # print(random_level_host) # list with full paths random_level_host_paths = {} for level in random_level_host : random_level_host_paths . update ({ level : [ f \" { config [ 'HOST' ][ 'host_genomes' ] }{ host } .fna\" for host in random_level_host [ level ]]}) # add known viruses for level in random_level_host : to_add = [] for host in random_level_host [ level ]: try : # virus_sample = random.sample(hostvir_data[host]['virus_id'], len(random_level_host[level]) if len(random_level_host[level]) < reps else reps) #virus_sample = random.sample(hostvir_data[host]['virus_id'], 1) virus_sample = random . sample ( hostvir_data [ host ][ 'virus_id' ], len ( hostvir_data [ host ][ 'virus_id' ])) to_add . extend ( virus_sample ) except : continue random_level_host_paths [ level ] . extend ([ f \" { config [ 'VIRUS' ][ 'virus_genomes' ] }{ virus } .fna\" for virus in to_add ]) random_level_host [ level ] . extend ( to_add ) print ( random_level_host ) # list of filenames to be used filenames = list ( random_level_host . values ()) # print(filenames) # list of paths to be returned filepaths = list ( random_level_host_paths . values ()) # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] temp_files_path = [ item for sublist in filepaths for item in sublist ] filenames = temp_files filepaths = temp_files_path print ( filenames ) # get list of taxid (labels in fastDNA) labels = [] for org in filenames : try : labels . append ( \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ org ][ \"lineage_names\" ][ - 1 ]))) except KeyError : labels . append ( \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , virus_data [ org ][ \"host\" ][ \"lineage_names\" ][ - 1 ]))) #labels = [\"_\".join(re.split(' |\\; |\\. |\\, ', host_data[host][\"lineage_names\"][-1])) for host in filenames] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filepaths , labels","title":"hybrid_filtering()"},{"location":"reference/make-model/#make-model.main_procedure","text":"Main function of the module that runs model making. Parameters: Name Type Description Default input_dir str Path to directory with all host genomes. required out_dir str Path to directory where all output files are saved (chosen genomes - .fasta file, taxid list - .txt file, model file - .bin file) required filter str A taxonomy level by which filtering is conducted / A flag to filter through this function Todo filter argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future required dim int Dimensionality of vectors to be used during the training process. required length int Length of fragments of the genomes to be used during the training process. required minn int Minimum size of a k-mer to be used during the training process. required maxn int Maximum size of a k-mer to be used during the training process (it is advised to be kept the same as minn and less than 15, otherwise fastDNA fails ). required epoch int Number of training epochs (each added epoch increases runtime significantly, but in most cases increases model quality). required thread int Number of CPU threads to be used during training process (more threads - faster training, but higher CPU usage) required reps int A number of representatives chosen randomly at selected level (defined by filter ) required rm bool Remove potentially redundant files after model creation. Default is false and it is advised to be set default. required save_vec bool Enables saving of a readable model file .vec . Enabling this may significantly increase execution time. Default is 'false'. required Todo filter argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future Source code in fastdna-faiss\\make-model.py def main_procedure ( input_dir : str , out_dir : str , filter : str , dim : int , length : int , minn : int , maxn : int , epoch : int , thread : int , reps : int , rm : bool , save_vec : bool ): \"\"\"Main function of the module that runs model making. Args: input_dir: Path to directory with all host genomes. out_dir: Path to directory where all output files are saved (chosen genomes - `.fasta` file, taxid list - `.txt` file, model file - `.bin` file) filter: A taxonomy level by which filtering is conducted / A flag to filter through this function !!! todo `filter` argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future dim: Dimensionality of vectors to be used during the training process. length: Length of fragments of the genomes to be used during the training process. minn: Minimum size of a k-mer to be used during the training process. maxn: Maximum size of a k-mer to be used during the training process (it is advised to be kept the same as `minn` and **less than 15, otherwise fastDNA fails**). epoch: Number of training epochs (each added epoch increases runtime significantly, but in most cases increases model quality). thread: Number of CPU threads to be used during training process (more threads - faster training, but higher CPU usage) reps: A number of representatives chosen randomly at selected level (defined by `filter`) rm: Remove potentially redundant files after model creation. Default is `false` and it is advised to be set default. save_vec: Enables saving of a readable model file `.vec`. Enabling this may significantly increase execution time. Default is 'false'. !!! todo `filter` argument is ambiguous at this moment. This is not final, this will act as an actual filter value in the future \"\"\" # colorama init () # timeit start = timer () out_path = Path ( out_dir ) if not out_path . exists (): os . system ( f \"mkdir { str ( out_path ) } \" ) filenames = [] labels = [] if filter not in [ \"none\" , \"hybrid\" , \"debug\" ]: filenames , labels = tax_filtering ( filter , reps ) if filter == \"none\" : filenames , labels = no_filtering ( input_dir ) if filter == \"hybrid\" : filenames , labels = hybrid_filtering ( filter , reps ) if filter == \"debug\" : filenames , labels = debug_filtering ( filter ) # parse selected files and merge them into single fasta file; create labels file # records = [list(SeqIO.parse(f\"D:/praktyki2020/edwards2016/host/fasta/{file}.fna\", \"fasta\"))[0] for file in filenames] # for file, label in zip(filenames, labels): # print(f\"{file} - {label}\") if filter not in [ \"hybrid\" , \"debug\" ]: par = Parallel ( n_jobs =- 1 , verbose = 11 , pre_dispatch = 'all' , batch_size = \"auto\" , backend = \"loky\" )( delayed ( fasta_parallel )( f \" { input_dir }{ file } .fna\" ) for file in filenames ) if filter in [ 'hybrid' , \"debug\" ]: par = Parallel ( n_jobs =- 1 , verbose = 11 , pre_dispatch = 'all' , batch_size = \"auto\" , backend = \"loky\" )( delayed ( fasta_parallel )( file ) for file in filenames ) # print(par) # print(len(records)) # print(records) filtered_fasta_file = f \"random_train- { filter } -dim_ { dim } -len_ { length } .fasta\" with open ( f \" { out_dir }{ filtered_fasta_file } \" , \"w+\" ) as w_fh : SeqIO . write ( par , w_fh , \"fasta\" ) labels_file = f \"random_labels- { filter } -dim_ { dim } -len_ { length } .txt\" with open ( f \" { out_dir }{ labels_file } \" , \"w\" ) as fh : for label in labels : fh . write ( label + \" \\n \" ) # run fastDNA training model_file = f \"random_model- { filter } -dim_ { dim } -len_ { length } -epoch { epoch } \" if save_vec : os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna supervised -input { out_dir }{ filtered_fasta_file } -labels { out_dir }{ labels_file } -output { out_dir }{ model_file } -dim { dim } -length { length } -minn { minn } -maxn { maxn } -epoch { epoch } -thread { thread } -saveVec\" ) else : os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna supervised -input { out_dir }{ filtered_fasta_file } -labels { out_dir }{ labels_file } -output { out_dir }{ model_file } -dim { dim } -length { length } -minn { minn } -maxn { maxn } -epoch { epoch } -thread { thread } \" ) # par = Parallel(n_jobs=-1)(delayed(SeqIO.write)(records, \"D:/praktyki2020/edwards2016/host/random_phylum-training_fastDNA.fasta\", \"fasta\") for record in records) # SeqIO.write(records, \"X:/edwards2016/host/random_phylum-training_fastDNA.fasta\", \"fasta\") # print(f\"Written {len(records)} records.\") if rm : print ( \"removing\" ) os . system ( f \"rm { out_dir }{ filtered_fasta_file } \" ) os . system ( f \"rm { out_dir }{ labels_file } \" ) end = timer () runtime = end - start print ( f \" { Fore . GREEN } [make-model] Done in { runtime : .6f } \" )","title":"main_procedure()"},{"location":"reference/make-model/#make-model.no_filtering","text":"Edwards' dataset of host is not filtered and all genomes from selected directory are passed to model training. Parameters: Name Type Description Default input_dir str Path to directory with all host genomes. required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def no_filtering ( input_dir : str ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is not filtered and all genomes from selected directory are passed to model training. Args: input_dir: Path to directory with all host genomes. Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" filenames = [ path . split ( \"/\" )[ - 1 ] . split ( \".\" )[ 0 ] for path in glob . glob ( f \" { input_dir } *.fna\" )] print ( filenames ) # labels = [host_data[host][\"taxid\"] for host in filenames] labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] return filenames , labels","title":"no_filtering()"},{"location":"reference/make-model/#make-model.tax_filtering","text":"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Parameters: Name Type Description Default filter str A taxonomy level by which filtering is conducted required reps int A number of representatives chosen randomly at selected level (defined by filter ) required Returns: Type Description Tuple[List[str], List[str]] A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. Source code in fastdna-faiss\\make-model.py def tax_filtering ( filter : str , reps : int ) -> Tuple [ List [ str ], List [ str ]]: \"\"\"Edwards' dataset of host is filtered to certain taxonomy level and specific host genomes that represent taxonomy level are randomly chosen. Args: filter: A taxonomy level by which filtering is conducted reps: A number of representatives chosen randomly at selected level (defined by `filter`) Returns: Tuple[List[str], List[str]]: A list of ncbi_id of selected hosts genomes and a list of taxid of selected hosts. \"\"\" # filtering all hosts by a chosen level filter_host = defaultdict ( list ) for host in host_data : level = host_data [ host ][ \"lineage_names\" ][ all_tax_levels [ filter ]] # tax level code filter_host [ level ] . append ( host ) # random sampling of a single host from a level random_level_host = { level : random . sample ( filter_host [ level ], len ( filter_host [ level ]) if len ( filter_host [ level ]) < reps else reps ) for level in filter_host } print ( random_level_host ) # list of filenames to be used filenames = list ( random_level_host . values ()) # print(filenames) # flatten if needed if isinstance ( filenames [ 0 ], list ): temp_files = [ item for sublist in filenames for item in sublist ] filenames = temp_files print ( filenames ) # get list of taxid (labels in fastDNA) labels = [ \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , host_data [ host ][ \"lineage_names\" ][ - 1 ])) for host in filenames ] # labels = [host_data[host][\"taxid\"] for host in filenames] print ( len ( labels )) return filenames , labels","title":"tax_filtering()"},{"location":"reference/random_sampling/","text":"random_sampling main_procedure ( wd , host , virus , full , host_dir , virus_dir , length , n_vir_samples , n_host_samples , n_nuc_threshold ) Main function of the module that samples genomes randomly: Parameters: Name Type Description Default wd str Working directory path required host bool Flag, which allows sampling only host genomes Obsolete In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. required virus bool Flag, which allows sampling only virus genomes. required full bool Flag, which allows sampling both virus and host genomes. Obsolete In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. required host_dir str Path to directory where sampled host fragments will be saved required virus_dir str Path to directory where sampled virus fragments will be saved required length int Length of sampled fragments required n_vir_samples int Number of samples to take from a virus genome required n_host_samples int Number of samples to take from a host genome required n_nuc_threshold float Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) required Source code in fastdna-faiss\\random_sampling.py def main_procedure ( wd : str , host : bool , virus : bool , full : bool , host_dir : str , virus_dir : str , length : int , n_vir_samples : int , n_host_samples : int , n_nuc_threshold : float ): \"\"\"Main function of the module that samples genomes randomly: Args: wd: Working directory path host: Flag, which allows sampling only host genomes !!! p-obsolete \"Obsolete\" In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. virus: Flag, which allows sampling only virus genomes. full: Flag, which allows sampling both virus and host genomes. !!! p-obsolete \"Obsolete\" In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. host_dir: Path to directory where sampled host fragments will be saved virus_dir: Path to directory where sampled virus fragments will be saved length: Length of sampled fragments n_vir_samples: Number of samples to take from a virus genome n_host_samples: Number of samples to take from a host genome n_nuc_threshold: Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) \"\"\" # colorama init () # timer start = timer () # importing json data about hosts utils . get_host_data () final_records = [] # parallel sampling records of all files and dumping them into one file if host : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_host_samples , wd , virus , n_nuc_threshold ) for file in glob . glob ( f \" { host_dir } *.fna\" )) # for host for sublist in new_records : final_records . extend ( sublist ) # host_file = Path(f\"{wd}host/samples/host_samples.fasta\") # if host_file.exists(): # os.system(f\"{wd}host/samples/host_samples.fasta\") with open ( f \" { wd } host/samples/host_samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( final_records , w_fh , \"fasta\" ) # mapping samples to nbci ids and dumping them into a file; edit 10.11.21 - much faster p_records = list ( SeqIO . parse ( f \" { wd } host/samples/host_samples.fasta\" , \"fasta\" )) ids_records = [ record . id . split ( \".\" )[ 0 ] for record in p_records ] d = {} for index , value in enumerate ( ids_records ): d [ index ] = value # for id in set(ids_records): # keys = [index for index, value in enumerate(ids_records) if value == id] # for key in keys: # d[key] = id with open ( f \" { wd } host/maps/sample_map.json\" , \"w\" , encoding = 'utf-8' ) as fh : json . dump ( d , fh , indent = 4 ) if virus : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_vir_samples , wd , virus , n_nuc_threshold ) for file in glob . glob ( f \" { virus_dir } *.fna\" )) if full : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_host_samples , wd , n_nuc_threshold , virus = False ) for file in glob . glob ( f \" { host_dir } *.fna\" )) # for host for sublist in new_records : final_records . extend ( sublist ) with open ( f \" { wd } host/samples/host_samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( final_records , w_fh , \"fasta\" ) # mapping samples to nbci ids and dumping them into a file; edit 10.11.21 - much faster p_records = list ( SeqIO . parse ( f \" { wd } host/samples/host_samples.fasta\" , \"fasta\" )) ids_records = [ record . id . split ( \".\" )[ 0 ] for record in p_records ] d = {} for index , value in enumerate ( ids_records ): d [ index ] = value # for id in set(ids_records): # keys = [index for index, value in enumerate(ids_records) if value == id] # for key in keys: # d[key] = id with open ( f \" { wd } host/maps/sample_map.json\" , \"w\" , encoding = 'utf-8' ) as fh : json . dump ( d , fh , indent = 4 ) new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_vir_samples , wd , n_nuc_threshold , virus = True ) for file in glob . glob ( f \" { virus_dir } *.fna\" )) # for virus, but second slower # for sublist in new_records: # with open(f\"X:/edwards2016/virus/samples/{sublist[0].id}_samples.fasta\", \"a\") as w_fh: # SeqIO.write(sublist, w_fh, \"fasta\") end = timer () runtime = end - start print ( f \" { Fore . GREEN } [random-sampling] Done in { runtime : .6f } seconds\" ) sample_sequences ( file , length , n , wd , n_nuc_threshold , virus ) Function reads each given fasta file, randomly samples n subsequences of a defined length, creates new records with those subsequences and puts these new records into a list (which is finally returned). Parameters: Name Type Description Default file str Full path to a fasta file required wd str Working directory path required length int Length of a sampled subsequence required n int Number of subsequences to be sampled required n_nuc_threshold float Ambiguous nucleotide content threshold in sampled sequences (in percents) required virus bool Flag which enables or disables virus genomes sampling required Returns: Type Description list[SeqRecord] Returns list of newly created biopython SeqRecord , each contains sampled subsequences. Source code in fastdna-faiss\\random_sampling.py def sample_sequences ( file : str , length : int , n : int , wd : str , n_nuc_threshold : float , virus : bool , ) -> List [ SeqRecord ]: \"\"\"Function reads each given fasta file, randomly samples n subsequences of a defined length, creates new records with those subsequences and puts these new records into a list (which is finally returned). Args: file (str): Full path to a fasta file wd (str): Working directory path length (int): Length of a sampled subsequence n (int): Number of subsequences to be sampled n_nuc_threshold (float): Ambiguous nucleotide content threshold in sampled sequences (in percents) virus (bool): Flag which enables or disables virus genomes sampling Returns: list[SeqRecord]: Returns list of newly created biopython `SeqRecord`, each contains sampled subsequences. \"\"\" new_records = [] record = SeqIO . read ( file , \"fasta\" ) for i in range ( n ): new_seq = None valid = False pick = None while not valid : pick = secrets . choice ( range ( 0 , len ( record . seq ) - length )) new_seq = Seq ( str ( record . seq [ pick : pick + length ])) n_content = new_seq . count ( \"N\" ) if n_content / length < n_nuc_threshold : valid = True else : print ( f \"Too high N content ( { n_content / length } %). Sampling again\" ) desc = f ' { record . description } sample_ { i } gen_pos:( { pick } : { pick + length } )' new_record = SeqRecord ( id = record . id , seq = new_seq , description = desc ) new_records . append ( new_record ) if virus : # if virus, this is possible with open ( f \" { wd } virus/samples/ { new_records [ 0 ] . id } _samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( new_records , w_fh , \"fasta\" ) return new_records","title":"random_sampling"},{"location":"reference/random_sampling/#random_sampling_1","text":"","title":"random_sampling"},{"location":"reference/random_sampling/#random_sampling.main_procedure","text":"Main function of the module that samples genomes randomly: Parameters: Name Type Description Default wd str Working directory path required host bool Flag, which allows sampling only host genomes Obsolete In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. required virus bool Flag, which allows sampling only virus genomes. required full bool Flag, which allows sampling both virus and host genomes. Obsolete In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. required host_dir str Path to directory where sampled host fragments will be saved required virus_dir str Path to directory where sampled virus fragments will be saved required length int Length of sampled fragments required n_vir_samples int Number of samples to take from a virus genome required n_host_samples int Number of samples to take from a host genome required n_nuc_threshold float Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) required Source code in fastdna-faiss\\random_sampling.py def main_procedure ( wd : str , host : bool , virus : bool , full : bool , host_dir : str , virus_dir : str , length : int , n_vir_samples : int , n_host_samples : int , n_nuc_threshold : float ): \"\"\"Main function of the module that samples genomes randomly: Args: wd: Working directory path host: Flag, which allows sampling only host genomes !!! p-obsolete \"Obsolete\" In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. virus: Flag, which allows sampling only virus genomes. full: Flag, which allows sampling both virus and host genomes. !!! p-obsolete \"Obsolete\" In current vision of the whole process, this parameter is obsolete. Using it might be undesirable and cause program to fail. Might be removed in later version. host_dir: Path to directory where sampled host fragments will be saved virus_dir: Path to directory where sampled virus fragments will be saved length: Length of sampled fragments n_vir_samples: Number of samples to take from a virus genome n_host_samples: Number of samples to take from a host genome n_nuc_threshold: Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) \"\"\" # colorama init () # timer start = timer () # importing json data about hosts utils . get_host_data () final_records = [] # parallel sampling records of all files and dumping them into one file if host : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_host_samples , wd , virus , n_nuc_threshold ) for file in glob . glob ( f \" { host_dir } *.fna\" )) # for host for sublist in new_records : final_records . extend ( sublist ) # host_file = Path(f\"{wd}host/samples/host_samples.fasta\") # if host_file.exists(): # os.system(f\"{wd}host/samples/host_samples.fasta\") with open ( f \" { wd } host/samples/host_samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( final_records , w_fh , \"fasta\" ) # mapping samples to nbci ids and dumping them into a file; edit 10.11.21 - much faster p_records = list ( SeqIO . parse ( f \" { wd } host/samples/host_samples.fasta\" , \"fasta\" )) ids_records = [ record . id . split ( \".\" )[ 0 ] for record in p_records ] d = {} for index , value in enumerate ( ids_records ): d [ index ] = value # for id in set(ids_records): # keys = [index for index, value in enumerate(ids_records) if value == id] # for key in keys: # d[key] = id with open ( f \" { wd } host/maps/sample_map.json\" , \"w\" , encoding = 'utf-8' ) as fh : json . dump ( d , fh , indent = 4 ) if virus : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_vir_samples , wd , virus , n_nuc_threshold ) for file in glob . glob ( f \" { virus_dir } *.fna\" )) if full : new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_host_samples , wd , n_nuc_threshold , virus = False ) for file in glob . glob ( f \" { host_dir } *.fna\" )) # for host for sublist in new_records : final_records . extend ( sublist ) with open ( f \" { wd } host/samples/host_samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( final_records , w_fh , \"fasta\" ) # mapping samples to nbci ids and dumping them into a file; edit 10.11.21 - much faster p_records = list ( SeqIO . parse ( f \" { wd } host/samples/host_samples.fasta\" , \"fasta\" )) ids_records = [ record . id . split ( \".\" )[ 0 ] for record in p_records ] d = {} for index , value in enumerate ( ids_records ): d [ index ] = value # for id in set(ids_records): # keys = [index for index, value in enumerate(ids_records) if value == id] # for key in keys: # d[key] = id with open ( f \" { wd } host/maps/sample_map.json\" , \"w\" , encoding = 'utf-8' ) as fh : json . dump ( d , fh , indent = 4 ) new_records = Parallel ( n_jobs =- 1 , verbose = True )( delayed ( sample_sequences )( file , length , n_vir_samples , wd , n_nuc_threshold , virus = True ) for file in glob . glob ( f \" { virus_dir } *.fna\" )) # for virus, but second slower # for sublist in new_records: # with open(f\"X:/edwards2016/virus/samples/{sublist[0].id}_samples.fasta\", \"a\") as w_fh: # SeqIO.write(sublist, w_fh, \"fasta\") end = timer () runtime = end - start print ( f \" { Fore . GREEN } [random-sampling] Done in { runtime : .6f } seconds\" )","title":"main_procedure()"},{"location":"reference/random_sampling/#random_sampling.sample_sequences","text":"Function reads each given fasta file, randomly samples n subsequences of a defined length, creates new records with those subsequences and puts these new records into a list (which is finally returned). Parameters: Name Type Description Default file str Full path to a fasta file required wd str Working directory path required length int Length of a sampled subsequence required n int Number of subsequences to be sampled required n_nuc_threshold float Ambiguous nucleotide content threshold in sampled sequences (in percents) required virus bool Flag which enables or disables virus genomes sampling required Returns: Type Description list[SeqRecord] Returns list of newly created biopython SeqRecord , each contains sampled subsequences. Source code in fastdna-faiss\\random_sampling.py def sample_sequences ( file : str , length : int , n : int , wd : str , n_nuc_threshold : float , virus : bool , ) -> List [ SeqRecord ]: \"\"\"Function reads each given fasta file, randomly samples n subsequences of a defined length, creates new records with those subsequences and puts these new records into a list (which is finally returned). Args: file (str): Full path to a fasta file wd (str): Working directory path length (int): Length of a sampled subsequence n (int): Number of subsequences to be sampled n_nuc_threshold (float): Ambiguous nucleotide content threshold in sampled sequences (in percents) virus (bool): Flag which enables or disables virus genomes sampling Returns: list[SeqRecord]: Returns list of newly created biopython `SeqRecord`, each contains sampled subsequences. \"\"\" new_records = [] record = SeqIO . read ( file , \"fasta\" ) for i in range ( n ): new_seq = None valid = False pick = None while not valid : pick = secrets . choice ( range ( 0 , len ( record . seq ) - length )) new_seq = Seq ( str ( record . seq [ pick : pick + length ])) n_content = new_seq . count ( \"N\" ) if n_content / length < n_nuc_threshold : valid = True else : print ( f \"Too high N content ( { n_content / length } %). Sampling again\" ) desc = f ' { record . description } sample_ { i } gen_pos:( { pick } : { pick + length } )' new_record = SeqRecord ( id = record . id , seq = new_seq , description = desc ) new_records . append ( new_record ) if virus : # if virus, this is possible with open ( f \" { wd } virus/samples/ { new_records [ 0 ] . id } _samples.fasta\" , \"w\" ) as w_fh : SeqIO . write ( new_records , w_fh , \"fasta\" ) return new_records","title":"sample_sequences()"},{"location":"reference/utils/","text":"utils get_config () Reads important settings and variables to run the analysis properly Returns: Type Description dict Returns dictionary of program variables parsed from config.cfg Source code in fastdna-faiss\\utils.py def get_config () -> dict : \"\"\"Reads important settings and variables to run the analysis properly Returns: dict: Returns dictionary of program variables parsed from `config.cfg` \"\"\" config = configparser . ConfigParser () config . read ( \"config.cfg\" ) config_dict = { section : dict ( config . items ( section )) for section in config . sections ()} return config_dict get_config_obj () Creates program configuration object from configuration file Returns: Type Description ConfigParser Returns ConfigParser object created from config.cfg Source code in fastdna-faiss\\utils.py def get_config_obj () -> configparser . ConfigParser : \"\"\"Creates program configuration object from configuration file Returns: ConfigParser: Returns ConfigParser object created from `config.cfg` \"\"\" config = configparser . ConfigParser () config . read ( \"config.cfg\" ) return config get_host_data () Reads Edwards' dataset of host information. Returns: Type Description dict Returns dictionary of data parsed from host.json Source code in fastdna-faiss\\utils.py def get_host_data () -> dict : \"\"\"Reads Edwards' dataset of host information. Returns: dict: Returns dictionary of data parsed from `host.json` \"\"\" with open ( \"host.json\" , \"r\" ) as fh : host_data = json . load ( fh ) return host_data get_hostname_data () Reads modified dataset of host information (organism name as a key). Returns: Type Description dict Returns dictionary of data parsed from hostname.json Source code in fastdna-faiss\\utils.py def get_hostname_data () -> dict : \"\"\"Reads modified dataset of host information (organism name as a key). Returns: dict: Returns dictionary of data parsed from `hostname.json` \"\"\" with open ( \"hostname.json\" , \"r\" ) as fh : hostname_data = json . load ( fh ) return hostname_data get_hostvir_data () Reads modified dataset of host information (additional information about infecting viruses). Returns: Type Description dict Returns dictionary of data parsed from hostvir.json Source code in fastdna-faiss\\utils.py def get_hostvir_data () -> dict : \"\"\"Reads modified dataset of host information (additional information about infecting viruses). Returns: dict: Returns dictionary of data parsed from `hostvir.json` \"\"\" with open ( 'hostvir.json' , 'r' ) as fh : hostvir_data = json . load ( fh ) return hostvir_data get_tax_data () Reads modified dataset of host information (taxid as a key). Returns: Type Description dict Returns dictionary of data parsed from tax.json Source code in fastdna-faiss\\utils.py def get_tax_data () -> dict : \"\"\"Reads modified dataset of host information (taxid as a key). Returns: dict: Returns dictionary of data parsed from `tax.json` \"\"\" with open ( \"tax.json\" , \"r\" ) as fh : tax_data = json . load ( fh ) return tax_data get_virus_data () Reads Edwards' dataset of virus information. Returns: Type Description dict Returns dictionary of data parsed from virus.json Source code in fastdna-faiss\\utils.py def get_virus_data () -> dict : \"\"\"Reads Edwards' dataset of virus information. Returns: dict: Returns dictionary of data parsed from `virus.json` \"\"\" with open ( \"virus.json\" , \"r\" ) as fh : virus_data = json . load ( fh ) return virus_data make_hostname_json () Creates hostname.json file which is a modified Edwards' host.json file where keys are represented as organism name but ncbi_id information is still retained as one of the values Source code in fastdna-faiss\\utils.py def make_hostname_json (): \"\"\"Creates `hostname.json` file which is a modified Edwards' `host.json` file where keys are represented as organism name but ncbi_id information is still retained as one of the values \"\"\" host_data = get_host_data () keys = list ( host_data . keys ()) for key in keys : temp_name = host_data [ key ][ 'lineage_names' ][ - 1 ] host_data [ key ][ \"ncbi_id\" ] = key name = \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , temp_name )) host_data [ name ] = host_data . pop ( key ) with open ( \"hostname.json\" , \"w\" ) as fh : json . dump ( host_data , fh , indent = 4 ) make_hostvir_json () Creates hostvir.json file which is a modified Edwards' host.json file with additional information about infecting viruses. Each record has a value with a list of infecting viruses. Source code in fastdna-faiss\\utils.py def make_hostvir_json (): \"\"\"Creates `hostvir.json` file which is a modified Edwards' `host.json` file with additional information about infecting viruses. Each record has a value with a list of infecting viruses. \"\"\" host_data = get_host_data () virus_data = get_virus_data () for host in host_data : lineage_name = host_data [ host ][ 'lineage_names' ][ 6 ] viruses = [] for virus in virus_data : if virus_data [ virus ][ 'host' ][ 'organism_name' ] == lineage_name : viruses . append ( virus ) host_data [ host ][ 'virus_id' ] = viruses with open ( 'hostvir.json' , 'w' ) as fh : json . dump ( host_data , fh ) make_tax_json () Creates tax.json file which is a modified Edwards' host.json file where keys are represented as taxid but ncbi_id information is still retained as one of the values Source code in fastdna-faiss\\utils.py def make_tax_json (): \"\"\"Creates `tax.json` file which is a modified Edwards' `host.json` file where keys are represented as taxid but ncbi_id information is still retained as one of the values \"\"\" host_data = get_host_data () keys = list ( host_data . keys ()) for key in keys : taxid = host_data [ key ][ \"taxid\" ] host_data [ key ][ \"ncbi_id\" ] = host_data [ key ] . pop ( \"taxid\" ) host_data [ key ][ \"ncbi_id\" ] = key data = host_data [ key ] host_data [ taxid ] = host_data . pop ( key ) with open ( \"tax.json\" , \"w\" ) as fh : json . dump ( host_data , fh , indent = 4 ) time_this ( func ) UNUSED Decorator which returns information about execution of decorated function. Source code in fastdna-faiss\\utils.py def time_this ( func ): \"\"\"*UNUSED* Decorator which returns information about execution of decorated function. \"\"\" @functools . wraps ( func ) def wrapper_timer ( * args , ** kwargs ): start = timer () values = func ( * args , ** kwargs ) end = timer () runtime = end - start if values is None : print ( f \" { Fore . RED }{ func . __name__ !r} execution error\" ) else : print ( f \" { Fore . GREEN }{ func . __name__ !r} executed successfully in { runtime : .6f } seconds\" ) return values [ 0 ] return wrapper_timer","title":"utils"},{"location":"reference/utils/#utils_1","text":"","title":"utils"},{"location":"reference/utils/#utils.get_config","text":"Reads important settings and variables to run the analysis properly Returns: Type Description dict Returns dictionary of program variables parsed from config.cfg Source code in fastdna-faiss\\utils.py def get_config () -> dict : \"\"\"Reads important settings and variables to run the analysis properly Returns: dict: Returns dictionary of program variables parsed from `config.cfg` \"\"\" config = configparser . ConfigParser () config . read ( \"config.cfg\" ) config_dict = { section : dict ( config . items ( section )) for section in config . sections ()} return config_dict","title":"get_config()"},{"location":"reference/utils/#utils.get_config_obj","text":"Creates program configuration object from configuration file Returns: Type Description ConfigParser Returns ConfigParser object created from config.cfg Source code in fastdna-faiss\\utils.py def get_config_obj () -> configparser . ConfigParser : \"\"\"Creates program configuration object from configuration file Returns: ConfigParser: Returns ConfigParser object created from `config.cfg` \"\"\" config = configparser . ConfigParser () config . read ( \"config.cfg\" ) return config","title":"get_config_obj()"},{"location":"reference/utils/#utils.get_host_data","text":"Reads Edwards' dataset of host information. Returns: Type Description dict Returns dictionary of data parsed from host.json Source code in fastdna-faiss\\utils.py def get_host_data () -> dict : \"\"\"Reads Edwards' dataset of host information. Returns: dict: Returns dictionary of data parsed from `host.json` \"\"\" with open ( \"host.json\" , \"r\" ) as fh : host_data = json . load ( fh ) return host_data","title":"get_host_data()"},{"location":"reference/utils/#utils.get_hostname_data","text":"Reads modified dataset of host information (organism name as a key). Returns: Type Description dict Returns dictionary of data parsed from hostname.json Source code in fastdna-faiss\\utils.py def get_hostname_data () -> dict : \"\"\"Reads modified dataset of host information (organism name as a key). Returns: dict: Returns dictionary of data parsed from `hostname.json` \"\"\" with open ( \"hostname.json\" , \"r\" ) as fh : hostname_data = json . load ( fh ) return hostname_data","title":"get_hostname_data()"},{"location":"reference/utils/#utils.get_hostvir_data","text":"Reads modified dataset of host information (additional information about infecting viruses). Returns: Type Description dict Returns dictionary of data parsed from hostvir.json Source code in fastdna-faiss\\utils.py def get_hostvir_data () -> dict : \"\"\"Reads modified dataset of host information (additional information about infecting viruses). Returns: dict: Returns dictionary of data parsed from `hostvir.json` \"\"\" with open ( 'hostvir.json' , 'r' ) as fh : hostvir_data = json . load ( fh ) return hostvir_data","title":"get_hostvir_data()"},{"location":"reference/utils/#utils.get_tax_data","text":"Reads modified dataset of host information (taxid as a key). Returns: Type Description dict Returns dictionary of data parsed from tax.json Source code in fastdna-faiss\\utils.py def get_tax_data () -> dict : \"\"\"Reads modified dataset of host information (taxid as a key). Returns: dict: Returns dictionary of data parsed from `tax.json` \"\"\" with open ( \"tax.json\" , \"r\" ) as fh : tax_data = json . load ( fh ) return tax_data","title":"get_tax_data()"},{"location":"reference/utils/#utils.get_virus_data","text":"Reads Edwards' dataset of virus information. Returns: Type Description dict Returns dictionary of data parsed from virus.json Source code in fastdna-faiss\\utils.py def get_virus_data () -> dict : \"\"\"Reads Edwards' dataset of virus information. Returns: dict: Returns dictionary of data parsed from `virus.json` \"\"\" with open ( \"virus.json\" , \"r\" ) as fh : virus_data = json . load ( fh ) return virus_data","title":"get_virus_data()"},{"location":"reference/utils/#utils.make_hostname_json","text":"Creates hostname.json file which is a modified Edwards' host.json file where keys are represented as organism name but ncbi_id information is still retained as one of the values Source code in fastdna-faiss\\utils.py def make_hostname_json (): \"\"\"Creates `hostname.json` file which is a modified Edwards' `host.json` file where keys are represented as organism name but ncbi_id information is still retained as one of the values \"\"\" host_data = get_host_data () keys = list ( host_data . keys ()) for key in keys : temp_name = host_data [ key ][ 'lineage_names' ][ - 1 ] host_data [ key ][ \"ncbi_id\" ] = key name = \"_\" . join ( re . split ( ' |\\; |\\. |\\, ' , temp_name )) host_data [ name ] = host_data . pop ( key ) with open ( \"hostname.json\" , \"w\" ) as fh : json . dump ( host_data , fh , indent = 4 )","title":"make_hostname_json()"},{"location":"reference/utils/#utils.make_hostvir_json","text":"Creates hostvir.json file which is a modified Edwards' host.json file with additional information about infecting viruses. Each record has a value with a list of infecting viruses. Source code in fastdna-faiss\\utils.py def make_hostvir_json (): \"\"\"Creates `hostvir.json` file which is a modified Edwards' `host.json` file with additional information about infecting viruses. Each record has a value with a list of infecting viruses. \"\"\" host_data = get_host_data () virus_data = get_virus_data () for host in host_data : lineage_name = host_data [ host ][ 'lineage_names' ][ 6 ] viruses = [] for virus in virus_data : if virus_data [ virus ][ 'host' ][ 'organism_name' ] == lineage_name : viruses . append ( virus ) host_data [ host ][ 'virus_id' ] = viruses with open ( 'hostvir.json' , 'w' ) as fh : json . dump ( host_data , fh )","title":"make_hostvir_json()"},{"location":"reference/utils/#utils.make_tax_json","text":"Creates tax.json file which is a modified Edwards' host.json file where keys are represented as taxid but ncbi_id information is still retained as one of the values Source code in fastdna-faiss\\utils.py def make_tax_json (): \"\"\"Creates `tax.json` file which is a modified Edwards' `host.json` file where keys are represented as taxid but ncbi_id information is still retained as one of the values \"\"\" host_data = get_host_data () keys = list ( host_data . keys ()) for key in keys : taxid = host_data [ key ][ \"taxid\" ] host_data [ key ][ \"ncbi_id\" ] = host_data [ key ] . pop ( \"taxid\" ) host_data [ key ][ \"ncbi_id\" ] = key data = host_data [ key ] host_data [ taxid ] = host_data . pop ( key ) with open ( \"tax.json\" , \"w\" ) as fh : json . dump ( host_data , fh , indent = 4 )","title":"make_tax_json()"},{"location":"reference/utils/#utils.time_this","text":"UNUSED Decorator which returns information about execution of decorated function. Source code in fastdna-faiss\\utils.py def time_this ( func ): \"\"\"*UNUSED* Decorator which returns information about execution of decorated function. \"\"\" @functools . wraps ( func ) def wrapper_timer ( * args , ** kwargs ): start = timer () values = func ( * args , ** kwargs ) end = timer () runtime = end - start if values is None : print ( f \" { Fore . RED }{ func . __name__ !r} execution error\" ) else : print ( f \" { Fore . GREEN }{ func . __name__ !r} executed successfully in { runtime : .6f } seconds\" ) return values [ 0 ] return wrapper_timer","title":"time_this()"},{"location":"reference/workflow2/","text":"workflow2 batch_exec ( files , k_best , wd ) Batch fastdna predict-prob module execution Parameters: Name Type Description Default files Tuple[str] Tuple of paths to FASTA files to be used in prediction required k_best int Number of best results from prediction required wd str Path to working directory, which completes path to output file required Source code in fastdna-faiss\\workflow2.py def batch_exec ( files : Tuple [ str ], k_best : int , wd : str ): \"\"\"Batch fastdna predict-prob module execution Args: files: Tuple of paths to FASTA files to be used in prediction k_best: Number of best results from prediction wd: Path to working directory, which completes path to output file \"\"\" for file in files : run_predict_prob ( file , k_best , wd ) main_procedure ( wd , length , n_vir_samples , thread , n_nuc_threshold , k_best ) Main function of the module that runs: - filesystem creation for working directory - random sampling of virus genomes - fastna predict-prob Parameters: Name Type Description Default wd str Path to working directory required length int Length of fragments of the genomes required n_vir_samples int Number of samples to take from a virus genome required thread int Number of CPU threads to be used (more threads - faster execution, but higher CPU usage) required n_nuc_threshold float Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) required k_best int Number of best results from prediction required Source code in fastdna-faiss\\workflow2.py def main_procedure ( wd : str , length : int , n_vir_samples : int , thread : int , n_nuc_threshold : float , k_best : int ): \"\"\"Main function of the module that runs: - filesystem creation for working directory - random sampling of virus genomes - fastna predict-prob Args: wd: Path to working directory length: Length of fragments of the genomes n_vir_samples: Number of samples to take from a virus genome thread: Number of CPU threads to be used (more threads - faster execution, but higher CPU usage) n_nuc_threshold: Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) k_best: Number of best results from prediction \"\"\" # colorama init () # global timer total_start = timer () # create necessary directories in the main working directory dirs = [ \"samples\" , \"preds\" ] for dir in dirs : pathlib . Path ( f \" { wd } virus/ { dir } \" ) . mkdir ( parents = True , exist_ok = True ) pathlib . Path ( f \" { wd } rank\" ) . mkdir ( parents = True , exist_ok = True ) # SAMPLING random_sampling . main_procedure ( wd , False , True , False , config [ \"HOST\" ][ \"host_genomes\" ], config [ \"VIRUS\" ][ \"virus_genomes\" ], length , n_vir_samples , 0 , n_nuc_threshold ) # pred = Parallel(n_jobs=thread, verbose=True)(delayed(run_predict_prob)(file, k_best, wd) # for file in glob.glob(f\"{wd}virus/samples/*.fasta\")) pred = Parallel ( n_jobs = thread , verbose = True )( delayed ( batch_exec )( batch , k_best , wd ) for batch in partition_queries ( glob . glob ( f \" { wd } virus/samples/*.fasta\" ))) total_end = timer () total_runtime = total_end - total_start print ( f \" { Fore . GREEN } Total elapsed time: { total_runtime : .6f } seconds\" ) partition_queries ( files , partitions = 15 ) Partitions set of paths to FASTA files with virus genomes to be batched. Parameters: Name Type Description Default files Iterable[str] Iterable of paths FASTA files with virus genomes required partitions int Number of paths to be collected into a batch. Info Currently, it is a predefined parameter which equals a number of CPU threads. 15 Returns: Type Description ndarray n-dimensional Numpy array with batches of file paths Source code in fastdna-faiss\\workflow2.py def partition_queries ( files : Iterable [ str ], partitions : int = cpu_count () - 1 ) -> np . ndarray : \"\"\"Partitions set of paths to FASTA files with virus genomes to be batched. Args: files: Iterable of paths FASTA files with virus genomes partitions: Number of paths to be collected into a batch. !!! info Currently, it is a predefined parameter which equals a number of CPU threads. Returns: ndarray: n-dimensional Numpy array with batches of file paths \"\"\" partitions = np . array_split ( np . array ( files ), partitions ) # debug for partitions # print(partitions) # print([ar.shape for ar in partitions]) return partitions run_predict_prob ( file , k_best , wd ) Runs fastdna predict-prob module. This function is run from batch_exec function Parameters: Name Type Description Default file str Path to FASTA file to be used in prediction required k_best int Number of best results from prediction required wd str Path to working directory, which completes path to output file required Source code in fastdna-faiss\\workflow2.py def run_predict_prob ( file : str , k_best : int , wd : str ): \"\"\"Runs fastdna predict-prob module. This function is run from [`batch_exec` function](#workflow2.batch_exec) Args: file: Path to FASTA file to be used in prediction k_best: Number of best results from prediction wd: Path to working directory, which completes path to output file \"\"\" name = file . split ( \"/\" )[ - 1 ] . split ( \".\" )[ 0 ] os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna predict-prob { config [ 'GENERAL' ][ 'active_model' ] } { file } { k_best } > { wd } virus/preds/ { name } _pred.json\" )","title":"workflow2"},{"location":"reference/workflow2/#workflow2_1","text":"","title":"workflow2"},{"location":"reference/workflow2/#workflow2.batch_exec","text":"Batch fastdna predict-prob module execution Parameters: Name Type Description Default files Tuple[str] Tuple of paths to FASTA files to be used in prediction required k_best int Number of best results from prediction required wd str Path to working directory, which completes path to output file required Source code in fastdna-faiss\\workflow2.py def batch_exec ( files : Tuple [ str ], k_best : int , wd : str ): \"\"\"Batch fastdna predict-prob module execution Args: files: Tuple of paths to FASTA files to be used in prediction k_best: Number of best results from prediction wd: Path to working directory, which completes path to output file \"\"\" for file in files : run_predict_prob ( file , k_best , wd )","title":"batch_exec()"},{"location":"reference/workflow2/#workflow2.main_procedure","text":"Main function of the module that runs: - filesystem creation for working directory - random sampling of virus genomes - fastna predict-prob Parameters: Name Type Description Default wd str Path to working directory required length int Length of fragments of the genomes required n_vir_samples int Number of samples to take from a virus genome required thread int Number of CPU threads to be used (more threads - faster execution, but higher CPU usage) required n_nuc_threshold float Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) required k_best int Number of best results from prediction required Source code in fastdna-faiss\\workflow2.py def main_procedure ( wd : str , length : int , n_vir_samples : int , thread : int , n_nuc_threshold : float , k_best : int ): \"\"\"Main function of the module that runs: - filesystem creation for working directory - random sampling of virus genomes - fastna predict-prob Args: wd: Path to working directory length: Length of fragments of the genomes n_vir_samples: Number of samples to take from a virus genome thread: Number of CPU threads to be used (more threads - faster execution, but higher CPU usage) n_nuc_threshold: Maximum allowed ambiguous nucleotide content threshold in sampled sequences (in percents) k_best: Number of best results from prediction \"\"\" # colorama init () # global timer total_start = timer () # create necessary directories in the main working directory dirs = [ \"samples\" , \"preds\" ] for dir in dirs : pathlib . Path ( f \" { wd } virus/ { dir } \" ) . mkdir ( parents = True , exist_ok = True ) pathlib . Path ( f \" { wd } rank\" ) . mkdir ( parents = True , exist_ok = True ) # SAMPLING random_sampling . main_procedure ( wd , False , True , False , config [ \"HOST\" ][ \"host_genomes\" ], config [ \"VIRUS\" ][ \"virus_genomes\" ], length , n_vir_samples , 0 , n_nuc_threshold ) # pred = Parallel(n_jobs=thread, verbose=True)(delayed(run_predict_prob)(file, k_best, wd) # for file in glob.glob(f\"{wd}virus/samples/*.fasta\")) pred = Parallel ( n_jobs = thread , verbose = True )( delayed ( batch_exec )( batch , k_best , wd ) for batch in partition_queries ( glob . glob ( f \" { wd } virus/samples/*.fasta\" ))) total_end = timer () total_runtime = total_end - total_start print ( f \" { Fore . GREEN } Total elapsed time: { total_runtime : .6f } seconds\" )","title":"main_procedure()"},{"location":"reference/workflow2/#workflow2.partition_queries","text":"Partitions set of paths to FASTA files with virus genomes to be batched. Parameters: Name Type Description Default files Iterable[str] Iterable of paths FASTA files with virus genomes required partitions int Number of paths to be collected into a batch. Info Currently, it is a predefined parameter which equals a number of CPU threads. 15 Returns: Type Description ndarray n-dimensional Numpy array with batches of file paths Source code in fastdna-faiss\\workflow2.py def partition_queries ( files : Iterable [ str ], partitions : int = cpu_count () - 1 ) -> np . ndarray : \"\"\"Partitions set of paths to FASTA files with virus genomes to be batched. Args: files: Iterable of paths FASTA files with virus genomes partitions: Number of paths to be collected into a batch. !!! info Currently, it is a predefined parameter which equals a number of CPU threads. Returns: ndarray: n-dimensional Numpy array with batches of file paths \"\"\" partitions = np . array_split ( np . array ( files ), partitions ) # debug for partitions # print(partitions) # print([ar.shape for ar in partitions]) return partitions","title":"partition_queries()"},{"location":"reference/workflow2/#workflow2.run_predict_prob","text":"Runs fastdna predict-prob module. This function is run from batch_exec function Parameters: Name Type Description Default file str Path to FASTA file to be used in prediction required k_best int Number of best results from prediction required wd str Path to working directory, which completes path to output file required Source code in fastdna-faiss\\workflow2.py def run_predict_prob ( file : str , k_best : int , wd : str ): \"\"\"Runs fastdna predict-prob module. This function is run from [`batch_exec` function](#workflow2.batch_exec) Args: file: Path to FASTA file to be used in prediction k_best: Number of best results from prediction wd: Path to working directory, which completes path to output file \"\"\" name = file . split ( \"/\" )[ - 1 ] . split ( \".\" )[ 0 ] os . system ( f \" { config [ 'GENERAL' ][ 'fastdna_dir' ] } fastdna predict-prob { config [ 'GENERAL' ][ 'active_model' ] } { file } { k_best } > { wd } virus/preds/ { name } _pred.json\" )","title":"run_predict_prob()"}]}